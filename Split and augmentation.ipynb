{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWVpGV8X6zn4gRVUY3RQpx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrabonbiswas/Thesis/blob/main/Split%20and%20augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1c2Jp3ollP1",
        "outputId": "67c1ef14-42d3-4e20-a47c-a770bc0ece4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# üìå Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Step 2: Copy zip from Drive to Colab content\n",
        "!cp \"/content/drive/MyDrive/Thesis_Update/preprocessed/Maize_Preprocessed.zip\" \"/content/Maize_Preprocessed.zip\"\n"
      ],
      "metadata": {
        "id": "fijNlVHkl_Kp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Step 3: Extract ZIP in content\n",
        "import zipfile\n",
        "zip_path = \"/content/Maize_Preprocessed.zip\"\n",
        "extract_dir = \"/content/Maize_Preprocessed\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "ifN9YHV-o9KE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create dataframe from image paths\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "image_paths = glob(f'{'/content/Maize_Preprocessed/dataset'}/*/*.*')\n",
        "data = pd.DataFrame({\n",
        "    'filepath': image_paths,\n",
        "    'label': [os.path.basename(os.path.dirname(p)) for p in image_paths]\n",
        "})\n",
        "\n",
        "# Stratified Split\n",
        "train_df, temp_df = train_test_split(data, test_size=0.3, stratify=data['label'], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n"
      ],
      "metadata": {
        "id": "8255Tjs2TczM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Copy images to split folders\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def copy_images(df, split_name, base_dir='/content/split'):\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        class_dir = os.path.join(base_dir, split_name, row['label'])\n",
        "        os.makedirs(class_dir, exist_ok=True)\n",
        "        shutil.copy(row['filepath'], class_dir)\n",
        "\n",
        "copy_images(train_df, 'train')\n",
        "copy_images(val_df, 'val')\n",
        "copy_images(test_df, 'test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulnylHTxUeEz",
        "outputId": "0c193a54-b690-42cb-ac96-9369a520d648"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2931/2931 [00:04<00:00, 706.93it/s] \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 628/628 [00:00<00:00, 2644.83it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 629/629 [00:00<00:00, 1903.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation"
      ],
      "metadata": {
        "id": "ctlnCbGXWPNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# ‚úÖ Base directory of your extracted split dataset\n",
        "base_train_dir = '/content/split/train'\n",
        "\n",
        "# ‚úÖ Desired target per class\n",
        "TARGET_PER_CLASS = 2000\n",
        "\n",
        "# ‚úÖ Augmentation pipeline\n",
        "augment = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Rotate(limit=30, p=0.5),\n",
        "    A.RandomShadow(p=0.3),\n",
        "    A.ZoomBlur(p=0.2),\n",
        "   A.ShiftScaleRotate(p=0.3)\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGlNxSZ5WU_u",
        "outputId": "de5e81dc-f341-4d90-dadb-c58c17389359"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/split/train'\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"‚ùå Dataset path not found: {dataset_path}\")\n",
        "else:\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_dir = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            num_images = len([\n",
        "                f for f in os.listdir(class_dir)\n",
        "                if os.path.isfile(os.path.join(class_dir, f))\n",
        "            ])\n",
        "            class_counts[class_name] = num_images\n",
        "\n",
        "    print(f\"\\n‚úÖ Number of classes: {len(class_counts)}\")\n",
        "    print(\"üìä Images per class:\")\n",
        "    for cls, count in class_counts.items():\n",
        "        print(f\"  {cls}: {count} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12bMjUuY7iJ",
        "outputId": "36510b59-d1bf-4040-898d-179a72e3a30f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Number of classes: 4\n",
            "üìä Images per class:\n",
            "  Gray_Leaf_Spot: 2000 images\n",
            "  Healthy: 2000 images\n",
            "  Common_Rust: 2000 images\n",
            "  Blight: 2000 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Apply augmentation only to classes with fewer than target images\n",
        "for class_name in os.listdir(base_train_dir):\n",
        "    class_path = os.path.join(base_train_dir, class_name)\n",
        "    images = os.listdir(class_path)\n",
        "    current_count = len(images)\n",
        "\n",
        "    print(f\"üìÅ {class_name}: {current_count} images\")\n",
        "\n",
        "    if current_count >= TARGET_PER_CLASS:\n",
        "        continue  # Skip if already enough\n",
        "\n",
        "    to_generate = TARGET_PER_CLASS - current_count\n",
        "    img_paths = [os.path.join(class_path, img) for img in images]\n",
        "\n",
        "    for i in tqdm(range(to_generate), desc=f\"üîÑ Augmenting {class_name}\"):\n",
        "        img_path = random.choice(img_paths)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        augmented = augment(image=img)['image']\n",
        "        save_path = os.path.join(class_path, f'aug_{i}_{os.path.basename(img_path)}')\n",
        "        cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBqTP4yNW2Qv",
        "outputId": "49cdf253-adcf-4a5b-82f9-9e5ad3a9c8ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Gray_Leaf_Spot: 2000 images\n",
            "üìÅ Healthy: 2000 images\n",
            "üìÅ Common_Rust: 2000 images\n",
            "üìÅ Blight: 2000 images\n"
          ]
        }
      ]
    }
  ]
}